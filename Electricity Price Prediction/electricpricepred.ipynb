{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14553328,"sourceType":"datasetVersion","datasetId":9295406}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pmdarima","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:08.495824Z","iopub.execute_input":"2026-01-21T13:49:08.496154Z","iopub.status.idle":"2026-01-21T13:49:13.152944Z","shell.execute_reply.started":"2026-01-21T13:49:08.496121Z","shell.execute_reply":"2026-01-21T13:49:13.151974Z"}},"outputs":[{"name":"stdout","text":"Collecting pmdarima\n  Downloading pmdarima-2.1.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.5 kB)\nRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.5.3)\nRequirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (3.0.12)\nRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.0.2)\nRequirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.2.2)\nRequirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.6.1)\nRequirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.15.3)\nRequirement already satisfied: statsmodels>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (0.14.5)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.6.3)\nRequirement already satisfied: setuptools!=50.0.0,>=42 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (75.2.0)\nRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (26.0rc2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2025.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->pmdarima) (3.6.0)\nRequirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.14.5->pmdarima) (1.0.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19->pmdarima) (1.17.0)\nDownloading pmdarima-2.1.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (689 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m689.1/689.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pmdarima\nSuccessfully installed pmdarima-2.1.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport altair as alt\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:13.154855Z","iopub.execute_input":"2026-01-21T13:49:13.155196Z","iopub.status.idle":"2026-01-21T13:49:15.877449Z","shell.execute_reply.started":"2026-01-21T13:49:13.155158Z","shell.execute_reply":"2026-01-21T13:49:15.876616Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Utility functions","metadata":{}},{"cell_type":"code","source":"def load_smard_csv(file_name):\n    \"\"\"\n    Loads and cleans SMARD-specific CSV formatting.\n    \"\"\"\n    path = os.path.join(DATA_DIR, file_name)\n    df = pd.read_csv(path, sep=';', decimal=',', thousands='.')\n    \n    # Convert timestamps and set index\n    df['timestamp'] = pd.to_datetime(df['Datum von'], format='%d.%m.%Y %H:%M')\n    df = df.set_index('timestamp').drop(['Datum von', 'Datum bis'], axis=1)\n    \n    # Clean numeric data (replace SMARD '-' with NaN)\n    df = df.replace('-', np.nan).apply(pd.to_numeric, errors='coerce')\n    \n    # Resample to Hourly (Standard for Day-Ahead Markets)\n    return df.resample('h').mean()\n\ndef create_generalized_dataset():\n    \"\"\"\n    Merges all files and creates a base feature set.\n    \"\"\"\n    print(\"Loading datasets...\")\n    df_price = load_smard_csv(FILES['price'])\n    df_forecast = load_smard_csv(FILES['forecast'])\n    df_load = load_smard_csv(FILES['load'])\n    df_gen = load_smard_csv(FILES['gen'])\n\n    # Select relevant columns and rename for a clean API\n    data = pd.DataFrame(index=df_price.index)\n    data['target_price'] = df_price['Deutschland/Luxemburg [€/MWh] Originalauflösungen']\n    \n    # Forecasts (Known in advance - No shift needed for renewable forecasts)\n    data['fc_solar'] = df_forecast['Photovoltaik [MWh] Originalauflösungen']\n    data['fc_wind_on'] = df_forecast['Wind Onshore [MWh] Originalauflösungen']\n    data['fc_wind_off'] = df_forecast['Wind Offshore [MWh] Originalauflösungen']\n    \n    # Total renewable forecast\n    data['fc_renewables_total'] = data['fc_solar'] + data['fc_wind_on'] + data['fc_wind_off']\n    \n    # Demand and Conventional (Historical - Shifted by 24h to avoid leaking future data)\n    data['load_lag_24h'] = df_load['Netzlast [MWh] Originalauflösungen'].shift(24)\n    data['load_lag_168h'] = df_load['Netzlast [MWh] Originalauflösungen'].shift(168)\n    data['gen_lignite_lag_24h'] = df_gen['Braunkohle [MWh] Originalauflösungen'].shift(24)\n    data['gen_gas_lag_24h'] = df_gen['Erdgas [MWh] Originalauflösungen'].shift(24)\n    \n    # Target Lags (Crucial for Time Series)\n    data['price_lag_24h'] = data['target_price'].shift(24)\n    data['price_lag_168h'] = data['target_price'].shift(168)  # 1 week ago\n    data['price_lag_48h'] = data['target_price'].shift(48)    # 2 days ago\n\n    # FIXED: Net Load Forecast (using lagged load to avoid data leakage)\n    # This estimates residual demand after renewables\n    data['net_load_forecast'] = data['load_lag_24h'] - data['fc_renewables_total']\n    \n    # Rolling statistics (capture recent trends without leakage)\n    data['price_rolling_mean_24h'] = data['target_price'].shift(1).rolling(24).mean()\n    data['price_rolling_std_24h'] = data['target_price'].shift(1).rolling(24).std()\n    data['price_rolling_mean_168h'] = data['target_price'].shift(1).rolling(168).mean()\n    \n    # Calendar Features\n    data['hour'] = data.index.hour\n    data['day_of_week'] = data.index.dayofweek\n    data['month'] = data.index.month\n    data['is_weekend'] = data['day_of_week'].isin([5, 6]).astype(int)\n    \n    # Cyclical encoding for hour (helps capture daily patterns)\n    data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)\n    data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)\n    \n    # Cyclical encoding for month (helps capture seasonal patterns)\n    data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)\n    data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)\n\n    return data.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:15.878609Z","iopub.execute_input":"2026-01-21T13:49:15.879190Z","iopub.status.idle":"2026-01-21T13:49:15.896386Z","shell.execute_reply.started":"2026-01-21T13:49:15.879153Z","shell.execute_reply":"2026-01-21T13:49:15.894941Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Load Data","metadata":{}},{"cell_type":"code","source":"# Configuration\nDATA_DIR = '/kaggle/input/electricppd/smard_data'\nFILES = {\n    'price': 'Gro_handelspreise_202101010000_202601010000_Viertelstunde.csv',\n    'forecast': 'Prognostizierte_Erzeugung_Day-Ahead_202101010000_202601010000_Viertelstunde_Stunde.csv',\n    'gen': 'Realisierte_Erzeugung_202101010000_202601010000_Viertelstunde.csv',\n    'load': 'Realisierter_Stromverbrauch_202101010000_202601010000_Viertelstunde (1).csv'\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:15.899038Z","iopub.execute_input":"2026-01-21T13:49:15.899401Z","iopub.status.idle":"2026-01-21T13:49:15.912464Z","shell.execute_reply.started":"2026-01-21T13:49:15.899375Z","shell.execute_reply":"2026-01-21T13:49:15.911890Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Create the master dataset\nmaster_df = create_generalized_dataset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:15.913293Z","iopub.execute_input":"2026-01-21T13:49:15.913553Z","iopub.status.idle":"2026-01-21T13:49:20.403176Z","shell.execute_reply.started":"2026-01-21T13:49:15.913524Z","shell.execute_reply":"2026-01-21T13:49:20.402396Z"}},"outputs":[{"name":"stdout","text":"Loading datasets...\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### EDA","metadata":{}},{"cell_type":"code","source":"master_df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:20.404133Z","iopub.execute_input":"2026-01-21T13:49:20.404410Z","iopub.status.idle":"2026-01-21T13:49:20.435554Z","shell.execute_reply.started":"2026-01-21T13:49:20.404380Z","shell.execute_reply":"2026-01-21T13:49:20.434868Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                     target_price  fc_solar  fc_wind_on  fc_wind_off  \\\ntimestamp                                                              \n2021-01-08 00:00:00         50.53       0.0    1606.500     263.1250   \n2021-01-08 01:00:00         48.43       0.0    1583.375     285.4375   \n2021-01-08 02:00:00         47.24       0.0    1564.625     290.3125   \n\n                     fc_renewables_total  load_lag_24h  load_lag_168h  \\\ntimestamp                                                               \n2021-01-08 00:00:00            1869.6250    13187.4375     11142.3125   \n2021-01-08 01:00:00            1868.8125    12739.3125     10701.5000   \n2021-01-08 02:00:00            1854.9375    12636.4375     10262.4375   \n\n                     gen_lignite_lag_24h  gen_gas_lag_24h  price_lag_24h  ...  \\\ntimestamp                                                                 ...   \n2021-01-08 00:00:00            3644.1250        2703.9375          51.03  ...   \n2021-01-08 01:00:00            3555.6875        2713.7500          50.18  ...   \n2021-01-08 02:00:00            3414.0000        2675.8750          48.97  ...   \n\n                     price_rolling_std_24h  price_rolling_mean_168h  hour  \\\ntimestamp                                                                   \n2021-01-08 00:00:00              17.600125                52.078333     0   \n2021-01-08 01:00:00              17.624979                52.076310     1   \n2021-01-08 02:00:00              17.717830                52.077738     2   \n\n                     day_of_week  month  is_weekend  hour_sin  hour_cos  \\\ntimestamp                                                                 \n2021-01-08 00:00:00            4      1           0  0.000000  1.000000   \n2021-01-08 01:00:00            4      1           0  0.258819  0.965926   \n2021-01-08 02:00:00            4      1           0  0.500000  0.866025   \n\n                     month_sin  month_cos  \ntimestamp                                  \n2021-01-08 00:00:00        0.5   0.866025  \n2021-01-08 01:00:00        0.5   0.866025  \n2021-01-08 02:00:00        0.5   0.866025  \n\n[3 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target_price</th>\n      <th>fc_solar</th>\n      <th>fc_wind_on</th>\n      <th>fc_wind_off</th>\n      <th>fc_renewables_total</th>\n      <th>load_lag_24h</th>\n      <th>load_lag_168h</th>\n      <th>gen_lignite_lag_24h</th>\n      <th>gen_gas_lag_24h</th>\n      <th>price_lag_24h</th>\n      <th>...</th>\n      <th>price_rolling_std_24h</th>\n      <th>price_rolling_mean_168h</th>\n      <th>hour</th>\n      <th>day_of_week</th>\n      <th>month</th>\n      <th>is_weekend</th>\n      <th>hour_sin</th>\n      <th>hour_cos</th>\n      <th>month_sin</th>\n      <th>month_cos</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-01-08 00:00:00</th>\n      <td>50.53</td>\n      <td>0.0</td>\n      <td>1606.500</td>\n      <td>263.1250</td>\n      <td>1869.6250</td>\n      <td>13187.4375</td>\n      <td>11142.3125</td>\n      <td>3644.1250</td>\n      <td>2703.9375</td>\n      <td>51.03</td>\n      <td>...</td>\n      <td>17.600125</td>\n      <td>52.078333</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.5</td>\n      <td>0.866025</td>\n    </tr>\n    <tr>\n      <th>2021-01-08 01:00:00</th>\n      <td>48.43</td>\n      <td>0.0</td>\n      <td>1583.375</td>\n      <td>285.4375</td>\n      <td>1868.8125</td>\n      <td>12739.3125</td>\n      <td>10701.5000</td>\n      <td>3555.6875</td>\n      <td>2713.7500</td>\n      <td>50.18</td>\n      <td>...</td>\n      <td>17.624979</td>\n      <td>52.076310</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.258819</td>\n      <td>0.965926</td>\n      <td>0.5</td>\n      <td>0.866025</td>\n    </tr>\n    <tr>\n      <th>2021-01-08 02:00:00</th>\n      <td>47.24</td>\n      <td>0.0</td>\n      <td>1564.625</td>\n      <td>290.3125</td>\n      <td>1854.9375</td>\n      <td>12636.4375</td>\n      <td>10262.4375</td>\n      <td>3414.0000</td>\n      <td>2675.8750</td>\n      <td>48.97</td>\n      <td>...</td>\n      <td>17.717830</td>\n      <td>52.077738</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>0.5</td>\n      <td>0.866025</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 24 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"master_df.tail(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:20.436392Z","iopub.execute_input":"2026-01-21T13:49:20.436658Z","iopub.status.idle":"2026-01-21T13:49:20.454902Z","shell.execute_reply.started":"2026-01-21T13:49:20.436633Z","shell.execute_reply":"2026-01-21T13:49:20.454249Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                     target_price  fc_solar  fc_wind_on  fc_wind_off  \\\ntimestamp                                                              \n2025-12-31 21:00:00       79.7975       0.0   6812.8200    1339.7750   \n2025-12-31 22:00:00       81.3900       0.0   6957.8875    1347.2725   \n2025-12-31 23:00:00       76.4475       0.0   7298.6075    1371.8875   \n\n                     fc_renewables_total  load_lag_24h  load_lag_168h  \\\ntimestamp                                                               \n2025-12-31 21:00:00             8152.595    13252.2425     12349.7350   \n2025-12-31 22:00:00             8305.160    12795.5425     12194.0025   \n2025-12-31 23:00:00             8670.495    12253.7775     11676.1900   \n\n                     gen_lignite_lag_24h  gen_gas_lag_24h  price_lag_24h  ...  \\\ntimestamp                                                                 ...   \n2025-12-31 21:00:00            2075.6475        2388.4150        93.3225  ...   \n2025-12-31 22:00:00            2061.3225        2358.4850        92.0450  ...   \n2025-12-31 23:00:00            1891.7150        2161.3325        85.8075  ...   \n\n                     price_rolling_std_24h  price_rolling_mean_168h  hour  \\\ntimestamp                                                                   \n2025-12-31 21:00:00               8.973217                88.491563    21   \n2025-12-31 22:00:00               9.094905                88.561860    22   \n2025-12-31 23:00:00               9.156241                88.635565    23   \n\n                     day_of_week  month  is_weekend  hour_sin  hour_cos  \\\ntimestamp                                                                 \n2025-12-31 21:00:00            2     12           0 -0.707107  0.707107   \n2025-12-31 22:00:00            2     12           0 -0.500000  0.866025   \n2025-12-31 23:00:00            2     12           0 -0.258819  0.965926   \n\n                        month_sin  month_cos  \ntimestamp                                     \n2025-12-31 21:00:00 -2.449294e-16        1.0  \n2025-12-31 22:00:00 -2.449294e-16        1.0  \n2025-12-31 23:00:00 -2.449294e-16        1.0  \n\n[3 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target_price</th>\n      <th>fc_solar</th>\n      <th>fc_wind_on</th>\n      <th>fc_wind_off</th>\n      <th>fc_renewables_total</th>\n      <th>load_lag_24h</th>\n      <th>load_lag_168h</th>\n      <th>gen_lignite_lag_24h</th>\n      <th>gen_gas_lag_24h</th>\n      <th>price_lag_24h</th>\n      <th>...</th>\n      <th>price_rolling_std_24h</th>\n      <th>price_rolling_mean_168h</th>\n      <th>hour</th>\n      <th>day_of_week</th>\n      <th>month</th>\n      <th>is_weekend</th>\n      <th>hour_sin</th>\n      <th>hour_cos</th>\n      <th>month_sin</th>\n      <th>month_cos</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2025-12-31 21:00:00</th>\n      <td>79.7975</td>\n      <td>0.0</td>\n      <td>6812.8200</td>\n      <td>1339.7750</td>\n      <td>8152.595</td>\n      <td>13252.2425</td>\n      <td>12349.7350</td>\n      <td>2075.6475</td>\n      <td>2388.4150</td>\n      <td>93.3225</td>\n      <td>...</td>\n      <td>8.973217</td>\n      <td>88.491563</td>\n      <td>21</td>\n      <td>2</td>\n      <td>12</td>\n      <td>0</td>\n      <td>-0.707107</td>\n      <td>0.707107</td>\n      <td>-2.449294e-16</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2025-12-31 22:00:00</th>\n      <td>81.3900</td>\n      <td>0.0</td>\n      <td>6957.8875</td>\n      <td>1347.2725</td>\n      <td>8305.160</td>\n      <td>12795.5425</td>\n      <td>12194.0025</td>\n      <td>2061.3225</td>\n      <td>2358.4850</td>\n      <td>92.0450</td>\n      <td>...</td>\n      <td>9.094905</td>\n      <td>88.561860</td>\n      <td>22</td>\n      <td>2</td>\n      <td>12</td>\n      <td>0</td>\n      <td>-0.500000</td>\n      <td>0.866025</td>\n      <td>-2.449294e-16</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2025-12-31 23:00:00</th>\n      <td>76.4475</td>\n      <td>0.0</td>\n      <td>7298.6075</td>\n      <td>1371.8875</td>\n      <td>8670.495</td>\n      <td>12253.7775</td>\n      <td>11676.1900</td>\n      <td>1891.7150</td>\n      <td>2161.3325</td>\n      <td>85.8075</td>\n      <td>...</td>\n      <td>9.156241</td>\n      <td>88.635565</td>\n      <td>23</td>\n      <td>2</td>\n      <td>12</td>\n      <td>0</td>\n      <td>-0.258819</td>\n      <td>0.965926</td>\n      <td>-2.449294e-16</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 24 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"print(f\"Master dataframe from {master_df.index.min()} to {master_df.index.max()}\")\nprint(f\"Full Dataset Shape: {master_df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:20.455986Z","iopub.execute_input":"2026-01-21T13:49:20.456254Z","iopub.status.idle":"2026-01-21T13:49:20.465243Z","shell.execute_reply.started":"2026-01-21T13:49:20.456236Z","shell.execute_reply":"2026-01-21T13:49:20.464482Z"}},"outputs":[{"name":"stdout","text":"Master dataframe from 2021-01-08 00:00:00 to 2025-12-31 23:00:00\nFull Dataset Shape: (42811, 24)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"master_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:20.466143Z","iopub.execute_input":"2026-01-21T13:49:20.466360Z","iopub.status.idle":"2026-01-21T13:49:20.486039Z","shell.execute_reply.started":"2026-01-21T13:49:20.466342Z","shell.execute_reply":"2026-01-21T13:49:20.485444Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 42811 entries, 2021-01-08 00:00:00 to 2025-12-31 23:00:00\nData columns (total 24 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   target_price             42811 non-null  float64\n 1   fc_solar                 42811 non-null  float64\n 2   fc_wind_on               42811 non-null  float64\n 3   fc_wind_off              42811 non-null  float64\n 4   fc_renewables_total      42811 non-null  float64\n 5   load_lag_24h             42811 non-null  float64\n 6   load_lag_168h            42811 non-null  float64\n 7   gen_lignite_lag_24h      42811 non-null  float64\n 8   gen_gas_lag_24h          42811 non-null  float64\n 9   price_lag_24h            42811 non-null  float64\n 10  price_lag_168h           42811 non-null  float64\n 11  price_lag_48h            42811 non-null  float64\n 12  net_load_forecast        42811 non-null  float64\n 13  price_rolling_mean_24h   42811 non-null  float64\n 14  price_rolling_std_24h    42811 non-null  float64\n 15  price_rolling_mean_168h  42811 non-null  float64\n 16  hour                     42811 non-null  int32  \n 17  day_of_week              42811 non-null  int32  \n 18  month                    42811 non-null  int32  \n 19  is_weekend               42811 non-null  int64  \n 20  hour_sin                 42811 non-null  float64\n 21  hour_cos                 42811 non-null  float64\n 22  month_sin                42811 non-null  float64\n 23  month_cos                42811 non-null  float64\ndtypes: float64(20), int32(3), int64(1)\nmemory usage: 7.7 MB\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"master_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:20.488506Z","iopub.execute_input":"2026-01-21T13:49:20.489043Z","iopub.status.idle":"2026-01-21T13:49:20.562493Z","shell.execute_reply.started":"2026-01-21T13:49:20.489016Z","shell.execute_reply":"2026-01-21T13:49:20.561647Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"       target_price      fc_solar    fc_wind_on   fc_wind_off  \\\ncount  42811.000000  42811.000000  42811.000000  42811.000000   \nmean     119.821928   1687.115563   2986.904932    703.635016   \nstd      101.186744   2580.089898   2400.599259    468.947243   \nmin     -500.000000      0.000000     40.312500      3.250000   \n25%       67.035000      0.000000   1118.375000    269.687500   \n50%       95.800000     64.312500   2252.125000    652.312500   \n75%      138.150000   2726.000000   4279.093750   1129.343750   \nmax      936.280000  12611.187500  11654.312500   1708.625000   \n\n       fc_renewables_total  load_lag_24h  load_lag_168h  gen_lignite_lag_24h  \\\ncount         42811.000000  42811.000000   42811.000000         42811.000000   \nmean           5377.655511  13558.031436   13556.685526          2387.203196   \nstd            3325.418656   2380.432196    2384.221533           886.225228   \nmin              80.125000   7725.687500    7725.687500           469.437500   \n25%            2544.468750  11607.187500   11603.272500          1655.468750   \n50%            4910.937500  13553.500000   13553.700000          2534.375000   \n75%            7728.093750  15363.125000   15361.718750          3093.343750   \nmax           18747.500000  20329.875000   20329.875000          4293.312500   \n\n       gen_gas_lag_24h  price_lag_24h  ...  price_rolling_std_24h  \\\ncount     42811.000000   42811.000000  ...           42811.000000   \nmean       1565.786322     119.802584  ...              36.525813   \nstd         864.651226     101.179625  ...              24.624905   \nmin         315.875000    -500.000000  ...               1.122431   \n25%         881.062500      67.005000  ...              19.320472   \n50%        1364.062500      95.800000  ...              30.885292   \n75%        2073.875000     138.130000  ...              46.931055   \nmax        5036.625000     936.280000  ...             262.937902   \n\n       price_rolling_mean_168h         hour   day_of_week         month  \\\ncount             42811.000000  42811.00000  42811.000000  42811.000000   \nmean                119.691216     11.50111      2.999650      6.604891   \nstd                  84.113413      6.92191      2.000438      3.444185   \nmin                  17.970655      0.00000      0.000000      1.000000   \n25%                  71.800268      6.00000      1.000000      4.000000   \n50%                  91.396071     12.00000      3.000000      7.000000   \n75%                 132.389315     18.00000      5.000000     10.000000   \nmax                 608.093095     23.00000      6.000000     12.000000   \n\n         is_weekend      hour_sin      hour_cos     month_sin     month_cos  \ncount  42811.000000  42811.000000  4.281100e+04  4.281100e+04  4.281100e+04  \nmean       0.285791     -0.000058 -1.011452e-04 -2.539619e-02 -6.053425e-04  \nstd        0.451796      0.707136  7.070944e-01  7.007044e-01  7.130157e-01  \nmin        0.000000     -1.000000 -1.000000e+00 -1.000000e+00 -1.000000e+00  \n25%        0.000000     -0.707107 -7.071068e-01 -8.660254e-01 -8.660254e-01  \n50%        0.000000      0.000000 -1.836970e-16 -2.449294e-16 -1.836970e-16  \n75%        1.000000      0.707107  7.071068e-01  5.000000e-01  8.660254e-01  \nmax        1.000000      1.000000  1.000000e+00  1.000000e+00  1.000000e+00  \n\n[8 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target_price</th>\n      <th>fc_solar</th>\n      <th>fc_wind_on</th>\n      <th>fc_wind_off</th>\n      <th>fc_renewables_total</th>\n      <th>load_lag_24h</th>\n      <th>load_lag_168h</th>\n      <th>gen_lignite_lag_24h</th>\n      <th>gen_gas_lag_24h</th>\n      <th>price_lag_24h</th>\n      <th>...</th>\n      <th>price_rolling_std_24h</th>\n      <th>price_rolling_mean_168h</th>\n      <th>hour</th>\n      <th>day_of_week</th>\n      <th>month</th>\n      <th>is_weekend</th>\n      <th>hour_sin</th>\n      <th>hour_cos</th>\n      <th>month_sin</th>\n      <th>month_cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>...</td>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>42811.00000</td>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>42811.000000</td>\n      <td>4.281100e+04</td>\n      <td>4.281100e+04</td>\n      <td>4.281100e+04</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>119.821928</td>\n      <td>1687.115563</td>\n      <td>2986.904932</td>\n      <td>703.635016</td>\n      <td>5377.655511</td>\n      <td>13558.031436</td>\n      <td>13556.685526</td>\n      <td>2387.203196</td>\n      <td>1565.786322</td>\n      <td>119.802584</td>\n      <td>...</td>\n      <td>36.525813</td>\n      <td>119.691216</td>\n      <td>11.50111</td>\n      <td>2.999650</td>\n      <td>6.604891</td>\n      <td>0.285791</td>\n      <td>-0.000058</td>\n      <td>-1.011452e-04</td>\n      <td>-2.539619e-02</td>\n      <td>-6.053425e-04</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>101.186744</td>\n      <td>2580.089898</td>\n      <td>2400.599259</td>\n      <td>468.947243</td>\n      <td>3325.418656</td>\n      <td>2380.432196</td>\n      <td>2384.221533</td>\n      <td>886.225228</td>\n      <td>864.651226</td>\n      <td>101.179625</td>\n      <td>...</td>\n      <td>24.624905</td>\n      <td>84.113413</td>\n      <td>6.92191</td>\n      <td>2.000438</td>\n      <td>3.444185</td>\n      <td>0.451796</td>\n      <td>0.707136</td>\n      <td>7.070944e-01</td>\n      <td>7.007044e-01</td>\n      <td>7.130157e-01</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-500.000000</td>\n      <td>0.000000</td>\n      <td>40.312500</td>\n      <td>3.250000</td>\n      <td>80.125000</td>\n      <td>7725.687500</td>\n      <td>7725.687500</td>\n      <td>469.437500</td>\n      <td>315.875000</td>\n      <td>-500.000000</td>\n      <td>...</td>\n      <td>1.122431</td>\n      <td>17.970655</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>67.035000</td>\n      <td>0.000000</td>\n      <td>1118.375000</td>\n      <td>269.687500</td>\n      <td>2544.468750</td>\n      <td>11607.187500</td>\n      <td>11603.272500</td>\n      <td>1655.468750</td>\n      <td>881.062500</td>\n      <td>67.005000</td>\n      <td>...</td>\n      <td>19.320472</td>\n      <td>71.800268</td>\n      <td>6.00000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>-0.707107</td>\n      <td>-7.071068e-01</td>\n      <td>-8.660254e-01</td>\n      <td>-8.660254e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>95.800000</td>\n      <td>64.312500</td>\n      <td>2252.125000</td>\n      <td>652.312500</td>\n      <td>4910.937500</td>\n      <td>13553.500000</td>\n      <td>13553.700000</td>\n      <td>2534.375000</td>\n      <td>1364.062500</td>\n      <td>95.800000</td>\n      <td>...</td>\n      <td>30.885292</td>\n      <td>91.396071</td>\n      <td>12.00000</td>\n      <td>3.000000</td>\n      <td>7.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.836970e-16</td>\n      <td>-2.449294e-16</td>\n      <td>-1.836970e-16</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>138.150000</td>\n      <td>2726.000000</td>\n      <td>4279.093750</td>\n      <td>1129.343750</td>\n      <td>7728.093750</td>\n      <td>15363.125000</td>\n      <td>15361.718750</td>\n      <td>3093.343750</td>\n      <td>2073.875000</td>\n      <td>138.130000</td>\n      <td>...</td>\n      <td>46.931055</td>\n      <td>132.389315</td>\n      <td>18.00000</td>\n      <td>5.000000</td>\n      <td>10.000000</td>\n      <td>1.000000</td>\n      <td>0.707107</td>\n      <td>7.071068e-01</td>\n      <td>5.000000e-01</td>\n      <td>8.660254e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>936.280000</td>\n      <td>12611.187500</td>\n      <td>11654.312500</td>\n      <td>1708.625000</td>\n      <td>18747.500000</td>\n      <td>20329.875000</td>\n      <td>20329.875000</td>\n      <td>4293.312500</td>\n      <td>5036.625000</td>\n      <td>936.280000</td>\n      <td>...</td>\n      <td>262.937902</td>\n      <td>608.093095</td>\n      <td>23.00000</td>\n      <td>6.000000</td>\n      <td>12.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 24 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Save the processed data\nmaster_df.to_csv('master_electricity_data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:20.563389Z","iopub.execute_input":"2026-01-21T13:49:20.563611Z","iopub.status.idle":"2026-01-21T13:49:21.628295Z","shell.execute_reply.started":"2026-01-21T13:49:20.563589Z","shell.execute_reply":"2026-01-21T13:49:21.627540Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"#### *Price vs Net Load Correlation*","metadata":{}},{"cell_type":"code","source":"# The data is sampled to 5000 points to keep the interactive output fast\nsample_df = master_df.sample(n=5000).reset_index()\n\nchart = alt.Chart(sample_df).mark_circle(opacity=0.3, size=20, color='teal').encode(\n    x=alt.X('net_load_forecast:Q', title='Net Load (Demand - Renewables) [MWh]'),\n    y=alt.Y('target_price:Q', title='Price (€/MWh)'),\n    tooltip=['timestamp:T', 'target_price:Q', 'net_load_forecast:Q']\n).properties(\n    title='Interactive Merit Order Effect',\n    width=600,\n    height=400\n).interactive()\n\nchart.save('merit_order_interactive.json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:21.629425Z","iopub.execute_input":"2026-01-21T13:49:21.629952Z","iopub.status.idle":"2026-01-21T13:49:22.077817Z","shell.execute_reply.started":"2026-01-21T13:49:21.629928Z","shell.execute_reply":"2026-01-21T13:49:22.076994Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"#### *Seasonality: Hourly Price Boxplots*","metadata":{}},{"cell_type":"code","source":"boxplot = alt.Chart(master_df).mark_boxplot().encode(\n    x=alt.X('hour:O', title='Hour of Day'),\n    y=alt.Y('target_price:Q', title='Price (€/MWh)', scale=alt.Scale(zero=False)),\n    color=alt.Color('hour:O', legend=None, scale=alt.Scale(scheme='viridis'))\n).properties(\n    title='Price Distribution by Hour of Day',\n    width=600, height=400\n).interactive()\n\nboxplot.save('hourly_seasonality.json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:22.078778Z","iopub.execute_input":"2026-01-21T13:49:22.079032Z","iopub.status.idle":"2026-01-21T13:49:23.938893Z","shell.execute_reply.started":"2026-01-21T13:49:22.079002Z","shell.execute_reply":"2026-01-21T13:49:23.938108Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"#### *Correlation Heatmap (top features only for readability)*","metadata":{}},{"cell_type":"code","source":"corr_cols = ['target_price', 'fc_renewables_total', 'net_load_forecast', \n             'price_lag_24h', 'price_lag_168h', 'load_lag_24h', \n             'gen_lignite_lag_24h', 'gen_gas_lag_24h', 'hour', 'month']\n\ncorr_matrix = master_df[corr_cols].corr().reset_index().melt(id_vars='index')\ncorr_matrix.columns = ['var1', 'var2', 'correlation']\n\nheatmap = alt.Chart(corr_matrix).mark_rect().encode(\n    x=alt.X('var1:N', title=None),\n    y=alt.Y('var2:N', title=None),\n    color=alt.Color('correlation:Q', scale=alt.Scale(scheme='redyellowgreen', domain=[-1, 1])),\n    tooltip=['var1', 'var2', alt.Tooltip('correlation:Q', format='.2f')]\n).properties(\n    title='Feature Correlation Matrix',\n    width=500, height=500\n).interactive()\n\nheatmap.save('correlation_heatmap.json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:23.940762Z","iopub.execute_input":"2026-01-21T13:49:23.940990Z","iopub.status.idle":"2026-01-21T13:49:23.987274Z","shell.execute_reply.started":"2026-01-21T13:49:23.940970Z","shell.execute_reply":"2026-01-21T13:49:23.986546Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"#### *Price Volatility over Time*","metadata":{}},{"cell_type":"code","source":"trend_df = master_df.tail(720).reset_index()\n\nline_chart = alt.Chart(trend_df).mark_line(strokeWidth=1.5, color='darkblue').encode(\n    x=alt.X('timestamp:T', title='Date'),\n    y=alt.Y('target_price:Q', title='Price (€/MWh)'),\n    tooltip=['timestamp:T', 'target_price:Q']\n).properties(\n    title='Electricity Price Trend (Last 30 Days)',\n    width=700, height=300\n).interactive()\n\nline_chart.save('price_trend.json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:23.988212Z","iopub.execute_input":"2026-01-21T13:49:23.988499Z","iopub.status.idle":"2026-01-21T13:49:24.177684Z","shell.execute_reply.started":"2026-01-21T13:49:23.988468Z","shell.execute_reply":"2026-01-21T13:49:24.177033Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"#### *Renewable Generation Impact*","metadata":{}},{"cell_type":"code","source":"# Sampled to 5000 points for performance\nscatter_sample = master_df.sample(n=min(5000, len(master_df)), random_state=42).reset_index()\n\nscatter_plot = alt.Chart(scatter_sample).mark_circle(opacity=0.3, size=20, color='green').encode(\n    x=alt.X('fc_renewables_total:Q', title='Total Renewable Forecast [MWh]'),\n    y=alt.Y('target_price:Q', title='Price (€/MWh)'),\n    tooltip=['timestamp:T', 'target_price:Q', 'fc_renewables_total:Q']\n).properties(\n    title='Impact of Renewable Generation on Prices',\n    width=600, height=400\n).interactive()\n\nscatter_plot.save('renewables_impact.json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:24.178454Z","iopub.execute_input":"2026-01-21T13:49:24.178766Z","iopub.status.idle":"2026-01-21T13:49:24.455008Z","shell.execute_reply.started":"2026-01-21T13:49:24.178745Z","shell.execute_reply":"2026-01-21T13:49:24.454231Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### Baseline Models\n\n- Naive\n- ARIMA\n- SARIMA\n- Prophet\n\n### Model Training","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport warnings\nfrom datetime import datetime\n\n# Statistical Models\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pmdarima import auto_arima\n\n# Prophet\nfrom prophet import Prophet\n\n# LightGBM\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n\nwarnings.filterwarnings('ignore')\n\n# --- CONFIGURATION ---\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\n# --- 1. DATA PREPARATION ---\n\ndef create_train_val_test_split(df, train_size=0.7, val_size=0.15):\n    \"\"\"\n    Creates chronological train/val/test split for time series.\n    Default: 70% train, 15% val, 15% test\n    \"\"\"\n    n = len(df)\n    train_end = int(n * train_size)\n    val_end = int(n * (train_size + val_size))\n    \n    train = df.iloc[:train_end]\n    val = df.iloc[train_end:val_end]\n    test = df.iloc[val_end:]\n    \n    print(\"=\"*70)\n    print(\"DATASET SPLIT SUMMARY\")\n    print(\"=\"*70)\n    print(f\"Train: {train.index[0]} to {train.index[-1]} ({len(train):,} samples, {len(train)/n*100:.1f}%)\")\n    print(f\"Val:   {val.index[0]} to {val.index[-1]} ({len(val):,} samples, {len(val)/n*100:.1f}%)\")\n    print(f\"Test:  {test.index[0]} to {test.index[-1]} ({len(test):,} samples, {len(test)/n*100:.1f}%)\")\n    print(\"=\"*70 + \"\\n\")\n    \n    return train, val, test\n\ndef prepare_data_for_models(train, val, test, target_col='target_price'):\n    \"\"\"Prepares datasets for different model types.\"\"\"\n    # For tree-based models (LightGBM)\n    feature_cols = [col for col in train.columns if col != target_col]\n    \n    X_train = train[feature_cols]\n    y_train = train[target_col]\n    \n    X_val = val[feature_cols]\n    y_val = val[target_col]\n    \n    X_test = test[feature_cols]\n    y_test = test[target_col]\n    \n    # For time series models (ARIMA, SARIMA, Prophet)\n    ts_train = train[target_col]\n    ts_val = val[target_col]\n    ts_test = test[target_col]\n    \n    return {\n        'X_train': X_train, 'y_train': y_train,\n        'X_val': X_val, 'y_val': y_val,\n        'X_test': X_test, 'y_test': y_test,\n        'ts_train': ts_train,\n        'ts_val': ts_val,\n        'ts_test': ts_test\n    }\n\n# --- 2. EVALUATION METRICS ---\n\ndef calculate_metrics(y_true, y_pred, model_name=\"Model\"):\n    \"\"\"Calculate comprehensive metrics.\"\"\"\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    mae = mean_absolute_error(y_true, y_pred)\n    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n    \n    return {\n        'Model': model_name,\n        'RMSE': rmse,\n        'MAE': mae,\n        'MAPE': mape\n    }\n\n# --- 3. BASELINE MODELS ---\n\ndef naive_baseline(data_dict):\n    \"\"\"Naive forecast: Use yesterday's price (24h lag).\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"MODEL 1: NAIVE BASELINE (24h Lag)\")\n    print(\"=\"*70)\n    \n    start_time = time.time()\n    \n    # Prediction is simply the price 24 hours ago\n    y_pred_val = data_dict['ts_train'].iloc[-len(data_dict['ts_val']):].values\n    y_pred_test = data_dict['ts_val'].iloc[-len(data_dict['ts_test']):].values\n    \n    elapsed = time.time() - start_time\n    \n    metrics_val = calculate_metrics(data_dict['y_val'], y_pred_val, \"Naive - Val\")\n    metrics_test = calculate_metrics(data_dict['y_test'], y_pred_test, \"Naive - Test\")\n    \n    print(f\"Training Time: {elapsed:.2f}s\")\n    print(f\"Val  → RMSE: {metrics_val['RMSE']:.2f}, MAE: {metrics_val['MAE']:.2f}, MAPE: {metrics_val['MAPE']:.2f}%\")\n    print(f\"Test → RMSE: {metrics_test['RMSE']:.2f}, MAE: {metrics_test['MAE']:.2f}, MAPE: {metrics_test['MAPE']:.2f}%\")\n    \n    return {\n        'model': None,\n        'predictions_val': y_pred_val,\n        'predictions_test': y_pred_test,\n        'metrics_val': metrics_val,\n        'metrics_test': metrics_test,\n        'training_time': elapsed\n    }\n\n# --- 4. ARIMA MODEL ---\n\ndef train_arima(data_dict, order=(2, 1, 2)):\n    \"\"\"Train ARIMA model with specified order.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(f\"MODEL 2: ARIMA{order}\")\n    print(\"=\"*70)\n    \n    start_time = time.time()\n    \n    # Fit on training data\n    print(\"Fitting ARIMA model...\")\n    model = ARIMA(data_dict['ts_train'], order=order)\n    model_fit = model.fit()\n    \n    # Forecast for validation period\n    y_pred_val = model_fit.forecast(steps=len(data_dict['ts_val']))\n    \n    # Refit on train + val for test predictions\n    ts_train_val = pd.concat([data_dict['ts_train'], data_dict['ts_val']])\n    model_test = ARIMA(ts_train_val, order=order)\n    model_test_fit = model_test.fit()\n    y_pred_test = model_test_fit.forecast(steps=len(data_dict['ts_test']))\n    \n    elapsed = time.time() - start_time\n    \n    metrics_val = calculate_metrics(data_dict['y_val'], y_pred_val, \"ARIMA - Val\")\n    metrics_test = calculate_metrics(data_dict['y_test'], y_pred_test, \"ARIMA - Test\")\n    \n    print(f\"Training Time: {elapsed:.2f}s\")\n    print(f\"Val  → RMSE: {metrics_val['RMSE']:.2f}, MAE: {metrics_val['MAE']:.2f}, MAPE: {metrics_val['MAPE']:.2f}%\")\n    print(f\"Test → RMSE: {metrics_test['RMSE']:.2f}, MAE: {metrics_test['MAE']:.2f}, MAPE: {metrics_test['MAPE']:.2f}%\")\n    \n    return {\n        'model': model_fit,\n        'predictions_val': y_pred_val,\n        'predictions_test': y_pred_test,\n        'metrics_val': metrics_val,\n        'metrics_test': metrics_test,\n        'training_time': elapsed\n    }\n\n# --- 5. SARIMA MODEL ---\n\ndef train_sarima(data_dict, order=(1, 1, 1), seasonal_order=(1, 1, 1, 24)):\n    \"\"\"Train SARIMA model (24h seasonality for hourly data).\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(f\"MODEL 3: SARIMA{order}x{seasonal_order}\")\n    print(\"=\"*70)\n    print(\"Warning: This may take several minutes...\")\n    \n    start_time = time.time()\n    \n    # Fit on training data\n    print(\"Fitting SARIMA model...\")\n    model = SARIMAX(data_dict['ts_train'], \n                    order=order, \n                    seasonal_order=seasonal_order,\n                    enforce_stationarity=False,\n                    enforce_invertibility=False)\n    model_fit = model.fit(disp=False)\n    \n    # Forecast for validation\n    y_pred_val = model_fit.forecast(steps=len(data_dict['ts_val']))\n    \n    # Refit on train + val for test\n    ts_train_val = pd.concat([data_dict['ts_train'], data_dict['ts_val']])\n    model_test = SARIMAX(ts_train_val, \n                         order=order, \n                         seasonal_order=seasonal_order,\n                         enforce_stationarity=False,\n                         enforce_invertibility=False)\n    model_test_fit = model_test.fit(disp=False)\n    y_pred_test = model_test_fit.forecast(steps=len(data_dict['ts_test']))\n    \n    elapsed = time.time() - start_time\n    \n    metrics_val = calculate_metrics(data_dict['y_val'], y_pred_val, \"SARIMA - Val\")\n    metrics_test = calculate_metrics(data_dict['y_test'], y_pred_test, \"SARIMA - Test\")\n    \n    print(f\"Training Time: {elapsed:.2f}s ({elapsed/60:.1f} min)\")\n    print(f\"Val  → RMSE: {metrics_val['RMSE']:.2f}, MAE: {metrics_val['MAE']:.2f}, MAPE: {metrics_val['MAPE']:.2f}%\")\n    print(f\"Test → RMSE: {metrics_test['RMSE']:.2f}, MAE: {metrics_test['MAE']:.2f}, MAPE: {metrics_test['MAPE']:.2f}%\")\n    \n    return {\n        'model': model_fit,\n        'predictions_val': y_pred_val,\n        'predictions_test': y_pred_test,\n        'metrics_val': metrics_val,\n        'metrics_test': metrics_test,\n        'training_time': elapsed\n    }\n\n# --- 6. PROPHET MODEL ---\n\ndef train_prophet(train, val, test, target_col='target_price'):\n    \"\"\"Train Facebook Prophet model.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"MODEL 4: PROPHET\")\n    print(\"=\"*70)\n    \n    start_time = time.time()\n    \n    # Prepare data for Prophet\n    prophet_train = train.reset_index()[['timestamp', target_col]]\n    prophet_train.columns = ['ds', 'y']\n    \n    # Train model\n    print(\"Fitting Prophet model...\")\n    model = Prophet(\n        yearly_seasonality=True,\n        weekly_seasonality=True,\n        daily_seasonality=True,\n        seasonality_mode='multiplicative'\n    )\n    model.fit(prophet_train)\n    \n    # Validation predictions\n    future_val = pd.DataFrame({'ds': val.index})\n    forecast_val = model.predict(future_val)\n    y_pred_val = forecast_val['yhat'].values\n    \n    # Refit on train + val for test\n    prophet_train_val = pd.concat([train, val]).reset_index()[['timestamp', target_col]]\n    prophet_train_val.columns = ['ds', 'y']\n    model_test = Prophet(\n        yearly_seasonality=True,\n        weekly_seasonality=True,\n        daily_seasonality=True,\n        seasonality_mode='multiplicative'\n    )\n    model_test.fit(prophet_train_val)\n    future_test = pd.DataFrame({'ds': test.index})\n    forecast_test = model_test.predict(future_test)\n    y_pred_test = forecast_test['yhat'].values\n    \n    elapsed = time.time() - start_time\n    \n    metrics_val = calculate_metrics(val[target_col], y_pred_val, \"Prophet - Val\")\n    metrics_test = calculate_metrics(test[target_col], y_pred_test, \"Prophet - Test\")\n    \n    print(f\"Training Time: {elapsed:.2f}s\")\n    print(f\"Val  → RMSE: {metrics_val['RMSE']:.2f}, MAE: {metrics_val['MAE']:.2f}, MAPE: {metrics_val['MAPE']:.2f}%\")\n    print(f\"Test → RMSE: {metrics_test['RMSE']:.2f}, MAE: {metrics_test['MAE']:.2f}, MAPE: {metrics_test['MAPE']:.2f}%\")\n    \n    return {\n        'model': model,\n        'predictions_val': y_pred_val,\n        'predictions_test': y_pred_test,\n        'metrics_val': metrics_val,\n        'metrics_test': metrics_test,\n        'training_time': elapsed\n    }\n\n# --- 7. LIGHTGBM WITH HYPERPARAMETER TUNING ---\n\ndef train_lightgbm(data_dict, tune_hyperparams=True):\n    \"\"\"Train LightGBM with optional hyperparameter tuning.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"MODEL 5: LIGHTGBM\" + (\" (with Hyperparameter Tuning)\" if tune_hyperparams else \"\"))\n    print(\"=\"*70)\n    \n    start_time = time.time()\n    \n    if tune_hyperparams:\n        print(\"Tuning hyperparameters using validation set...\")\n        \n        # Hyperparameter search space\n        param_grid = {\n            'num_leaves': [31, 50, 70],\n            'learning_rate': [0.01, 0.05, 0.1],\n            'n_estimators': [100, 300, 500],\n            'max_depth': [-1, 10, 20],\n            'min_child_samples': [20, 50, 100]\n        }\n        \n        best_score = float('inf')\n        best_params = None\n        \n        # Grid search (simplified - you can use optuna for better search)\n        from itertools import product\n        \n        param_combinations = [\n            {'num_leaves': 50, 'learning_rate': 0.05, 'n_estimators': 300, \n             'max_depth': 10, 'min_child_samples': 20},\n            {'num_leaves': 70, 'learning_rate': 0.01, 'n_estimators': 500, \n             'max_depth': -1, 'min_child_samples': 50},\n            {'num_leaves': 31, 'learning_rate': 0.1, 'n_estimators': 100, \n             'max_depth': 20, 'min_child_samples': 100}\n        ]\n        \n        for params in param_combinations:\n            model = lgb.LGBMRegressor(**params, random_state=RANDOM_STATE, verbose=-1)\n            model.fit(data_dict['X_train'], data_dict['y_train'])\n            y_pred = model.predict(data_dict['X_val'])\n            score = mean_squared_error(data_dict['y_val'], y_pred)\n            \n            if score < best_score:\n                best_score = score\n                best_params = params\n        \n        print(f\"Best params: {best_params}\")\n        print(f\"Best validation RMSE: {np.sqrt(best_score):.2f}\")\n        \n        final_params = best_params\n    else:\n        final_params = {\n            'num_leaves': 50,\n            'learning_rate': 0.05,\n            'n_estimators': 300,\n            'max_depth': 10,\n            'random_state': RANDOM_STATE,\n            'verbose': -1\n        }\n    \n    # Train final model on train set\n    print(\"Training final model...\")\n    model = lgb.LGBMRegressor(**final_params)\n    model.fit(\n        data_dict['X_train'], \n        data_dict['y_train'],\n        eval_set=[(data_dict['X_val'], data_dict['y_val'])],\n        callbacks=[lgb.early_stopping(50, verbose=False)]\n    )\n    \n    # Predictions\n    y_pred_val = model.predict(data_dict['X_val'])\n    \n    # Retrain on train + val for test\n    X_train_val = pd.concat([data_dict['X_train'], data_dict['X_val']])\n    y_train_val = pd.concat([data_dict['y_train'], data_dict['y_val']])\n    \n    model_final = lgb.LGBMRegressor(**final_params)\n    model_final.fit(X_train_val, y_train_val)\n    y_pred_test = model_final.predict(data_dict['X_test'])\n    \n    elapsed = time.time() - start_time\n    \n    metrics_val = calculate_metrics(data_dict['y_val'], y_pred_val, \"LightGBM - Val\")\n    metrics_test = calculate_metrics(data_dict['y_test'], y_pred_test, \"LightGBM - Test\")\n    \n    print(f\"Training Time: {elapsed:.2f}s\")\n    print(f\"Val  → RMSE: {metrics_val['RMSE']:.2f}, MAE: {metrics_val['MAE']:.2f}, MAPE: {metrics_val['MAPE']:.2f}%\")\n    print(f\"Test → RMSE: {metrics_test['RMSE']:.2f}, MAE: {metrics_test['MAE']:.2f}, MAPE: {metrics_test['MAPE']:.2f}%\")\n    \n    # Feature importance\n    feature_imp = pd.DataFrame({\n        'feature': data_dict['X_train'].columns,\n        'importance': model.feature_importances_\n    }).sort_values('importance', ascending=False)\n    \n    print(f\"\\nTop 10 Most Important Features:\")\n    print(feature_imp.head(10).to_string(index=False))\n    \n    return {\n        'model': model_final,\n        'predictions_val': y_pred_val,\n        'predictions_test': y_pred_test,\n        'metrics_val': metrics_val,\n        'metrics_test': metrics_test,\n        'training_time': elapsed,\n        'feature_importance': feature_imp\n    }\n\n# --- 8. VISUALIZATION ---\n\ndef plot_results(results, val, test, target_col='target_price'):\n    \"\"\"Create comprehensive visualization of all model predictions.\"\"\"\n    \n    fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n    \n    # Validation Set\n    ax = axes[0]\n    ax.plot(val.index, val[target_col], label='Actual', color='black', linewidth=2, alpha=0.7)\n    \n    colors = ['blue', 'green', 'red', 'purple', 'orange']\n    for (name, result), color in zip(results.items(), colors):\n        ax.plot(val.index, result['predictions_val'], label=name, \n                color=color, alpha=0.6, linewidth=1.5)\n    \n    ax.set_title('Validation Set Predictions', fontsize=14, fontweight='bold')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Price (€/MWh)')\n    ax.legend(loc='best')\n    ax.grid(alpha=0.3)\n    \n    # Test Set\n    ax = axes[1]\n    ax.plot(test.index, test[target_col], label='Actual', color='black', linewidth=2, alpha=0.7)\n    \n    for (name, result), color in zip(results.items(), colors):\n        ax.plot(test.index, result['predictions_test'], label=name, \n                color=color, alpha=0.6, linewidth=1.5)\n    \n    ax.set_title('Test Set Predictions', fontsize=14, fontweight='bold')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Price (€/MWh)')\n    ax.legend(loc='best')\n    ax.grid(alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig('model_comparison_predictions.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    print(\"\\nSaved: model_comparison_predictions.png\")\n\ndef create_comparison_table(results):\n    \"\"\"Create performance comparison table.\"\"\"\n    \n    metrics_list = []\n    for name, result in results.items():\n        metrics_list.append(result['metrics_val'])\n        metrics_list.append(result['metrics_test'])\n    \n    df_metrics = pd.DataFrame(metrics_list)\n    \n    # Create styled table\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.axis('tight')\n    ax.axis('off')\n    \n    table = ax.table(cellText=df_metrics.values, \n                     colLabels=df_metrics.columns,\n                     cellLoc='center',\n                     loc='center',\n                     bbox=[0, 0, 1, 1])\n    \n    table.auto_set_font_size(False)\n    table.set_fontsize(10)\n    table.scale(1, 2)\n    \n    # Color coding\n    for i in range(len(df_metrics)):\n        if 'Val' in df_metrics.iloc[i]['Model']:\n            for j in range(len(df_metrics.columns)):\n                table[(i+1, j)].set_facecolor('#E8F4F8')\n        else:\n            for j in range(len(df_metrics.columns)):\n                table[(i+1, j)].set_facecolor('#FFF4E6')\n    \n    plt.title('Model Performance Comparison', fontsize=14, fontweight='bold', pad=20)\n    plt.savefig('model_comparison_table.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    print(\"Saved: model_comparison_table.png\")\n    \n    return df_metrics\n\n# --- 9. MAIN EXECUTION ---\n\ndef run_complete_experiment(data_path='master_electricity_data.csv'):\n    \"\"\"Run complete model comparison experiment.\"\"\"\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"ELECTRICITY PRICE FORECASTING - COMPLETE MODEL COMPARISON\")\n    print(\"=\"*70 + \"\\n\")\n    \n    # Load data\n    print(\"Loading data...\")\n    df = pd.read_csv(data_path, index_col=0, parse_dates=True)\n    print(f\"Loaded {len(df):,} samples with {df.shape[1]} features\")\n    \n    # Create splits\n    train, val, test = create_train_val_test_split(df, train_size=0.7, val_size=0.15)\n    \n    # Prepare data\n    data_dict = prepare_data_for_models(train, val, test)\n    \n    # Store results\n    results = {}\n    \n    # Model 1: Naive Baseline\n    results['Naive'] = naive_baseline(data_dict)\n    \n    # Model 2: ARIMA\n    results['ARIMA'] = train_arima(data_dict, order=(2, 1, 2))\n    \n    # Model 3: SARIMA (may take time!)\n    results['SARIMA'] = train_sarima(data_dict, order=(1, 1, 1), seasonal_order=(1, 1, 1, 24))\n    \n    # Model 4: Prophet\n    results['Prophet'] = train_prophet(train, val, test)\n    \n    # Model 5: LightGBM\n    results['LightGBM'] = train_lightgbm(data_dict, tune_hyperparams=True)\n    \n    # Visualizations\n    print(\"\\n\" + \"=\"*70)\n    print(\"GENERATING VISUALIZATIONS\")\n    print(\"=\"*70)\n    plot_results(results, val, test)\n    comparison_df = create_comparison_table(results)\n    \n    # Final Summary\n    print(\"\\n\" + \"=\"*70)\n    print(\"FINAL SUMMARY\")\n    print(\"=\"*70)\n    print(\"\\nTest Set Performance:\")\n    print(comparison_df[comparison_df['Model'].str.contains('Test')].to_string(index=False))\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT COMPLETE!\")\n    print(\"=\"*70)\n    print(\"Output files generated:\")\n    print(\"  - model_comparison_predictions.png\")\n    print(\"  - model_comparison_table.png\")\n    \n    return results, comparison_df\n\n# --- RUN EXPERIMENT ---\nif __name__ == \"__main__\":\n    results, metrics_df = run_complete_experiment('master_electricity_data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:49:24.456208Z","iopub.execute_input":"2026-01-21T13:49:24.456520Z","iopub.status.idle":"2026-01-21T13:54:16.559301Z","shell.execute_reply.started":"2026-01-21T13:49:24.456490Z","shell.execute_reply":"2026-01-21T13:54:16.558649Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nELECTRICITY PRICE FORECASTING - COMPLETE MODEL COMPARISON\n======================================================================\n\nLoading data...\nLoaded 42,811 samples with 24 features\n======================================================================\nDATASET SPLIT SUMMARY\n======================================================================\nTrain: 2021-01-08 00:00:00 to 2024-07-07 18:00:00 (29,967 samples, 70.0%)\nVal:   2024-07-07 19:00:00 to 2025-04-08 09:00:00 (6,422 samples, 15.0%)\nTest:  2025-04-08 10:00:00 to 2025-12-31 23:00:00 (6,422 samples, 15.0%)\n======================================================================\n\n\n======================================================================\nMODEL 1: NAIVE BASELINE (24h Lag)\n======================================================================\nTraining Time: 0.00s\nVal  → RMSE: 78.05, MAE: 57.21, MAPE: 106497297821827744.00%\nTest → RMSE: 80.99, MAE: 57.92, MAPE: 500377128140826304.00%\n\n======================================================================\nMODEL 2: ARIMA(2, 1, 2)\n======================================================================\nFitting ARIMA model...\nTraining Time: 14.57s\nVal  → RMSE: 91.42, MAE: 74.31, MAPE: 44945541084187472.00%\nTest → RMSE: 51.17, MAE: 33.71, MAPE: 466954198551052224.00%\n\n======================================================================\nMODEL 3: SARIMA(1, 1, 1)x(1, 1, 1, 24)\n======================================================================\nWarning: This may take several minutes...\nFitting SARIMA model...\nTraining Time: 159.40s (2.7 min)\nVal  → RMSE: 182.65, MAE: 153.58, MAPE: 284509783501280640.00%\nTest → RMSE: 261.45, MAE: 222.85, MAPE: 589312318602199040.00%\n\n======================================================================\nMODEL 4: PROPHET\n======================================================================\nFitting Prophet model...\n","output_type":"stream"},{"name":"stderr","text":"13:52:26 - cmdstanpy - INFO - Chain [1] start processing\n13:52:59 - cmdstanpy - INFO - Chain [1] done processing\n13:53:01 - cmdstanpy - INFO - Chain [1] start processing\n13:54:06 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"Training Time: 102.65s\nVal  → RMSE: 59.90, MAE: 42.15, MAPE: 98289498668852512.00%\nTest → RMSE: 45.67, MAE: 33.55, MAPE: 310634773853171968.00%\n\n======================================================================\nMODEL 5: LIGHTGBM (with Hyperparameter Tuning)\n======================================================================\nTuning hyperparameters using validation set...\nBest params: {'num_leaves': 50, 'learning_rate': 0.05, 'n_estimators': 300, 'max_depth': 10, 'min_child_samples': 20}\nBest validation RMSE: 30.18\nTraining final model...\nTraining Time: 6.55s\nVal  → RMSE: 30.18, MAE: 16.78, MAPE: 18669765158820216.00%\nTest → RMSE: 19.99, MAE: 13.37, MAPE: 50557948203995352.00%\n\nTop 10 Most Important Features:\n                feature  importance\n  price_rolling_std_24h        1243\n price_rolling_mean_24h        1144\nprice_rolling_mean_168h        1090\n         price_lag_168h         943\n      net_load_forecast         906\n            day_of_week         882\n        gen_gas_lag_24h         840\n    fc_renewables_total         774\n    gen_lignite_lag_24h         765\n             fc_wind_on         752\n\n======================================================================\nGENERATING VISUALIZATIONS\n======================================================================\n\nSaved: model_comparison_predictions.png\nSaved: model_comparison_table.png\n\n======================================================================\nFINAL SUMMARY\n======================================================================\n\nTest Set Performance:\n          Model       RMSE        MAE         MAPE\n   Naive - Test  80.994028  57.916859 5.003771e+17\n   ARIMA - Test  51.167882  33.714502 4.669542e+17\n  SARIMA - Test 261.451386 222.849929 5.893123e+17\n Prophet - Test  45.674060  33.552242 3.106348e+17\nLightGBM - Test  19.987495  13.368429 5.055795e+16\n\n======================================================================\nEXPERIMENT COMPLETE!\n======================================================================\nOutput files generated:\n  - model_comparison_predictions.png\n  - model_comparison_table.png\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### Predictions January, 27th, 2026","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport warnings\n\n# Models\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom prophet import Prophet\nimport lightgbm as lgb\n\nwarnings.filterwarnings('ignore')\n\n# --- CONFIGURATION ---\nTARGET_DATE = '2026-01-27'  # Target prediction date\nRANDOM_STATE = 42\n\n# --- 1. LOAD TRAINED MODELS AND DATA ---\n\ndef load_full_dataset(data_path='master_electricity_data.csv'):\n    \"\"\"Load the complete dataset.\"\"\"\n    print(\"Loading master dataset...\")\n    df = pd.read_csv(data_path, index_col=0, parse_dates=True)\n    print(f\"Loaded {len(df):,} samples\")\n    print(f\"Date range: {df.index[0]} to {df.index[-1]}\")\n    return df\n\n# --- 2. PREDICT WITH TIME SERIES MODELS (ARIMA, SARIMA) ---\n\ndef predict_with_arima_sarima(df, target_date, target_col='target_price'):\n    \"\"\"Predict using ARIMA and SARIMA models.\"\"\"\n    \n    # Calculate steps ahead\n    last_date = df.index[-1]\n    target_datetime = pd.to_datetime(target_date)\n    hours_ahead = int((target_datetime - last_date).total_seconds() / 3600)\n    \n    print(f\"\\nPredicting {hours_ahead} hours ahead (from {last_date} to {target_datetime})\")\n    \n    if hours_ahead <= 0:\n        print(\"Error: Target date is in the past or present!\")\n        return None\n    \n    ts_data = df[target_col]\n    \n    results = {}\n    \n    # ARIMA\n    print(\"\\n[1/2] Training ARIMA model on full dataset...\")\n    arima_model = ARIMA(ts_data, order=(2, 1, 2))\n    arima_fit = arima_model.fit()\n    arima_forecast = arima_fit.forecast(steps=hours_ahead)\n    results['ARIMA'] = arima_forecast.iloc[-1]  # Last prediction = target date\n    print(f\"ARIMA prediction for {target_date}: €{results['ARIMA']:.2f}/MWh\")\n    \n    # SARIMA\n    print(\"\\n[2/2] Training SARIMA model on full dataset...\")\n    print(\"(This may take several minutes...)\")\n    sarima_model = SARIMAX(ts_data, \n                           order=(1, 1, 1), \n                           seasonal_order=(1, 1, 1, 24),\n                           enforce_stationarity=False,\n                           enforce_invertibility=False)\n    sarima_fit = sarima_model.fit(disp=False)\n    sarima_forecast = sarima_fit.forecast(steps=hours_ahead)\n    results['SARIMA'] = sarima_forecast.iloc[-1]\n    print(f\"SARIMA prediction for {target_date}: €{results['SARIMA']:.2f}/MWh\")\n    \n    return results, arima_forecast, sarima_forecast\n\n# --- 3. PREDICT WITH PROPHET ---\n\ndef predict_with_prophet(df, target_date, target_col='target_price'):\n    \"\"\"Predict using Prophet model.\"\"\"\n    \n    print(\"\\n[3/4] Training Prophet model on full dataset...\")\n    \n    # Prepare data\n    prophet_df = df.reset_index()[[df.index.name or 'timestamp', target_col]]\n    prophet_df.columns = ['ds', 'y']\n    \n    # Train model\n    model = Prophet(\n        yearly_seasonality=True,\n        weekly_seasonality=True,\n        daily_seasonality=True,\n        seasonality_mode='multiplicative'\n    )\n    model.fit(prophet_df)\n    \n    # Create future dataframe\n    last_date = df.index[-1]\n    target_datetime = pd.to_datetime(target_date)\n    hours_ahead = int((target_datetime - last_date).total_seconds() / 3600)\n    \n    future = model.make_future_dataframe(periods=hours_ahead, freq='h')\n    forecast = model.predict(future)\n    \n    # Get prediction for target date\n    target_pred = forecast[forecast['ds'] == target_datetime]['yhat'].values[0]\n    \n    print(f\"Prophet prediction for {target_date}: €{target_pred:.2f}/MWh\")\n    \n    return target_pred, forecast\n\n# --- 4. PREDICT WITH LIGHTGBM (Requires Feature Engineering) ---\n\ndef create_future_features(df, target_date, target_col='target_price'):\n    \"\"\"\n    Create features for future prediction.\n    Note: This requires assumptions about future renewable forecasts.\n    \"\"\"\n    \n    last_date = df.index[-1]\n    target_datetime = pd.to_datetime(target_date)\n    hours_ahead = int((target_datetime - last_date).total_seconds() / 3600)\n    \n    # Create future datetime index\n    future_index = pd.date_range(start=last_date + timedelta(hours=1), \n                                  periods=hours_ahead, \n                                  freq='h')\n    \n    # Initialize future dataframe with target column placeholder\n    future_df = pd.DataFrame(index=future_index)\n    future_df[target_col] = np.nan  # Initialize target column\n    \n    # Calendar features (we know these for future dates)\n    future_df['hour'] = future_df.index.hour\n    future_df['day_of_week'] = future_df.index.dayofweek\n    future_df['month'] = future_df.index.month\n    future_df['is_weekend'] = future_df['day_of_week'].isin([5, 6]).astype(int)\n    future_df['hour_sin'] = np.sin(2 * np.pi * future_df['hour'] / 24)\n    future_df['hour_cos'] = np.cos(2 * np.pi * future_df['hour'] / 24)\n    future_df['month_sin'] = np.sin(2 * np.pi * future_df['month'] / 12)\n    future_df['month_cos'] = np.cos(2 * np.pi * future_df['month'] / 12)\n    \n    # Lag features (use recent historical data)\n    last_prices = df[target_col].tail(168)  # Last week of prices\n    \n    # Initialize lag columns\n    future_df['price_lag_24h'] = np.nan\n    future_df['price_lag_168h'] = np.nan\n    future_df['price_lag_48h'] = np.nan\n    \n    for i, future_hour in enumerate(future_index):\n        # 24h lag\n        if i >= 24:\n            future_df.loc[future_hour, 'price_lag_24h'] = future_df.iloc[i - 24][target_col]\n        else:\n            lag_idx = len(last_prices) + i - 24\n            if lag_idx >= 0 and lag_idx < len(last_prices):\n                future_df.loc[future_hour, 'price_lag_24h'] = last_prices.iloc[lag_idx]\n            else:\n                future_df.loc[future_hour, 'price_lag_24h'] = df[target_col].iloc[-24 + i]\n        \n        # 168h lag\n        if i >= 168:\n            future_df.loc[future_hour, 'price_lag_168h'] = future_df.iloc[i - 168][target_col]\n        else:\n            lag_idx = len(last_prices) + i - 168\n            if lag_idx >= 0:\n                future_df.loc[future_hour, 'price_lag_168h'] = last_prices.iloc[lag_idx]\n            else:\n                # Use data from main df\n                historical_idx = len(df) + i - 168\n                if historical_idx >= 0:\n                    future_df.loc[future_hour, 'price_lag_168h'] = df[target_col].iloc[historical_idx]\n                else:\n                    future_df.loc[future_hour, 'price_lag_168h'] = df[target_col].mean()\n        \n        # 48h lag\n        if i >= 48:\n            future_df.loc[future_hour, 'price_lag_48h'] = future_df.iloc[i - 48][target_col]\n        else:\n            lag_idx = len(last_prices) + i - 48\n            if lag_idx >= 0 and lag_idx < len(last_prices):\n                future_df.loc[future_hour, 'price_lag_48h'] = last_prices.iloc[lag_idx]\n            else:\n                future_df.loc[future_hour, 'price_lag_48h'] = df[target_col].iloc[-48 + i]\n    \n    # Initialize all feature columns that will be needed\n    future_df['fc_solar'] = np.nan\n    future_df['fc_wind_on'] = np.nan\n    future_df['fc_wind_off'] = np.nan\n    future_df['load_lag_24h'] = np.nan\n    future_df['load_lag_168h'] = np.nan\n    future_df['gen_lignite_lag_24h'] = np.nan\n    future_df['gen_gas_lag_24h'] = np.nan\n    \n    # For renewable forecasts and load - use seasonal averages from historical data\n    # (In production, you'd get these from actual forecast data)\n    print(\"\\nNote: Using historical seasonal averages for renewable forecasts and load\")\n    print(\"      (In production, use actual forecast data)\")\n    \n    for idx in future_df.index:\n        hour = idx.hour\n        dow = idx.dayofweek\n        month = idx.month\n        \n        # Get similar historical periods\n        mask = (df.index.hour == hour) & (df.index.dayofweek == dow) & (df.index.month == month)\n        historical_similar = df[mask].tail(30)  # Last 30 similar hours\n        \n        if len(historical_similar) > 0:\n            future_df.loc[idx, 'fc_solar'] = historical_similar['fc_solar'].mean()\n            future_df.loc[idx, 'fc_wind_on'] = historical_similar['fc_wind_on'].mean()\n            future_df.loc[idx, 'fc_wind_off'] = historical_similar['fc_wind_off'].mean()\n            future_df.loc[idx, 'load_lag_24h'] = historical_similar['load_lag_24h'].mean()\n            future_df.loc[idx, 'load_lag_168h'] = historical_similar.get('load_lag_168h', historical_similar['load_lag_24h']).mean()\n            future_df.loc[idx, 'gen_lignite_lag_24h'] = historical_similar['gen_lignite_lag_24h'].mean()\n            future_df.loc[idx, 'gen_gas_lag_24h'] = historical_similar['gen_gas_lag_24h'].mean()\n        else:\n            # Fallback to overall averages\n            future_df.loc[idx, 'fc_solar'] = df['fc_solar'].mean()\n            future_df.loc[idx, 'fc_wind_on'] = df['fc_wind_on'].mean()\n            future_df.loc[idx, 'fc_wind_off'] = df['fc_wind_off'].mean()\n            future_df.loc[idx, 'load_lag_24h'] = df['load_lag_24h'].mean()\n            future_df.loc[idx, 'load_lag_168h'] = df.get('load_lag_168h', df['load_lag_24h']).mean()\n            future_df.loc[idx, 'gen_lignite_lag_24h'] = df['gen_lignite_lag_24h'].mean()\n            future_df.loc[idx, 'gen_gas_lag_24h'] = df['gen_gas_lag_24h'].mean()\n    \n    # Derived features\n    future_df['fc_renewables_total'] = future_df['fc_solar'] + future_df['fc_wind_on'] + future_df['fc_wind_off']\n    future_df['net_load_forecast'] = future_df['load_lag_24h'] - future_df['fc_renewables_total']\n    \n    # Rolling features (use last known values)\n    future_df['price_rolling_mean_24h'] = df[target_col].tail(24).mean()\n    future_df['price_rolling_std_24h'] = df[target_col].tail(24).std()\n    future_df['price_rolling_mean_168h'] = df[target_col].tail(168).mean()\n    \n    return future_df\n\ndef predict_with_lightgbm(df, target_date, target_col='target_price'):\n    \"\"\"Predict using LightGBM model.\"\"\"\n    \n    print(\"\\n[4/4] Training LightGBM model on full dataset...\")\n    \n    # Prepare training data\n    feature_cols = [col for col in df.columns if col != target_col]\n    X = df[feature_cols]\n    y = df[target_col]\n    \n    # Train model\n    params = {\n        'num_leaves': 50,\n        'learning_rate': 0.05,\n        'n_estimators': 300,\n        'max_depth': 10,\n        'random_state': RANDOM_STATE,\n        'verbose': -1\n    }\n    \n    model = lgb.LGBMRegressor(**params)\n    model.fit(X, y)\n    \n    # Create future features\n    future_df = create_future_features(df, target_date, target_col)\n    \n    # Iterative prediction (important for lag features)\n    predictions = []\n    \n    # Ensure all required columns exist before prediction\n    missing_cols = [col for col in feature_cols if col not in future_df.columns]\n    if missing_cols:\n        print(f\"Warning: Missing features {missing_cols}, filling with 0\")\n        for col in missing_cols:\n            future_df[col] = 0\n    \n    for i in range(len(future_df)):\n        # Get features for this hour - ensure correct order\n        X_pred = future_df.iloc[i:i+1][feature_cols]\n        pred = model.predict(X_pred)[0]\n        predictions.append(pred)\n        \n        # Update future_df with this prediction for subsequent lag calculations\n        future_df.iloc[i, future_df.columns.get_loc(target_col)] = pred\n    \n    # Get the final prediction for target date\n    target_datetime = pd.to_datetime(target_date)\n    target_pred = predictions[-1]  # Last prediction is for target date\n    \n    print(f\"LightGBM prediction for {target_date}: €{target_pred:.2f}/MWh\")\n    \n    return target_pred, future_df, predictions\n\n# --- 5. VISUALIZATION ---\n\ndef visualize_predictions(df, predictions_dict, target_date):\n    \"\"\"Create visualization showing historical data and predictions.\"\"\"\n    \n    fig, ax = plt.subplots(figsize=(16, 8))\n    \n    # Plot last 30 days of historical data\n    last_30_days = df.tail(720)  # 30 days * 24 hours\n    ax.plot(last_30_days.index, last_30_days['target_price'], \n            label='Historical Price', color='black', linewidth=2, alpha=0.7)\n    \n    # Mark target date\n    target_datetime = pd.to_datetime(target_date)\n    \n    # Plot predictions\n    colors = {'ARIMA': 'blue', 'SARIMA': 'green', 'Prophet': 'red', 'LightGBM': 'orange'}\n    \n    for model_name, pred_value in predictions_dict.items():\n        ax.scatter(target_datetime, pred_value, \n                  color=colors.get(model_name, 'purple'), \n                  s=200, marker='*', \n                  label=f'{model_name}: €{pred_value:.2f}/MWh',\n                  zorder=5, edgecolors='black', linewidths=1.5)\n    \n    # Formatting\n    ax.axvline(df.index[-1], color='gray', linestyle='--', alpha=0.5, label='Last Known Data')\n    ax.axvline(target_datetime, color='red', linestyle='--', alpha=0.5, label='Target Date')\n    \n    ax.set_title(f'Electricity Price Predictions for {target_date}', \n                fontsize=16, fontweight='bold', pad=20)\n    ax.set_xlabel('Date', fontsize=12)\n    ax.set_ylabel('Price (€/MWh)', fontsize=12)\n    ax.legend(loc='best', fontsize=10)\n    ax.grid(alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(f'prediction_{target_date}.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    \n    print(f\"\\nSaved visualization: prediction_{target_date}.png\")\n\ndef create_prediction_summary(predictions_dict, target_date):\n    \"\"\"Create a summary table of predictions.\"\"\"\n    \n    summary_df = pd.DataFrame({\n        'Model': list(predictions_dict.keys()),\n        'Predicted Price (€/MWh)': [f\"{v:.2f}\" for v in predictions_dict.values()]\n    })\n    \n    # Calculate statistics\n    prices = list(predictions_dict.values())\n    mean_pred = np.mean(prices)\n    std_pred = np.std(prices)\n    min_pred = np.min(prices)\n    max_pred = np.max(prices)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(f\"ELECTRICITY PRICE PREDICTIONS FOR {target_date}\")\n    print(\"=\"*70)\n    print(summary_df.to_string(index=False))\n    print(\"\\n\" + \"-\"*70)\n    print(f\"Ensemble Average:  €{mean_pred:.2f}/MWh\")\n    print(f\"Standard Deviation: €{std_pred:.2f}/MWh\")\n    print(f\"Range:             €{min_pred:.2f} - €{max_pred:.2f}/MWh\")\n    print(\"=\"*70)\n    \n    return summary_df, mean_pred\n\n# --- 6. MAIN PREDICTION PIPELINE ---\n\ndef predict_electricity_price(target_date='2026-01-27', \n                              data_path='master_electricity_data.csv',\n                              hourly_prediction=True):\n    \"\"\"\n    Main function to predict electricity price for a future date.\n    \n    Parameters:\n    -----------\n    target_date : str\n        Target date in format 'YYYY-MM-DD' or 'YYYY-MM-DD HH:MM:SS'\n    data_path : str\n        Path to the master dataset\n    hourly_prediction : bool\n        If True and no time specified, predicts for each hour of the day\n    \"\"\"\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"ELECTRICITY PRICE FORECASTING SYSTEM\")\n    print(\"=\"*70)\n    \n    # Load data\n    df = load_full_dataset(data_path)\n    \n    # If only date provided (no time), predict for noon or all hours\n    if len(target_date) == 10:  # Format: YYYY-MM-DD\n        if hourly_prediction:\n            print(f\"\\nGenerating hourly predictions for {target_date} (00:00 to 23:00)\")\n            target_date_full = f\"{target_date} 12:00:00\"  # Use noon for main prediction\n        else:\n            target_date_full = f\"{target_date} 12:00:00\"\n    else:\n        target_date_full = target_date\n    \n    # Run predictions\n    predictions = {}\n    \n    # Time series models\n    ts_results, arima_fc, sarima_fc = predict_with_arima_sarima(df, target_date_full)\n    predictions.update(ts_results)\n    \n    # Prophet\n    prophet_pred, prophet_fc = predict_with_prophet(df, target_date_full)\n    predictions['Prophet'] = prophet_pred\n    \n    # LightGBM\n    lgb_pred, future_features, lgb_preds = predict_with_lightgbm(df, target_date_full)\n    predictions['LightGBM'] = lgb_pred\n    \n    # Create summary\n    summary_df, ensemble_pred = create_prediction_summary(predictions, target_date_full)\n    \n    # Visualize\n    visualize_predictions(df, predictions, target_date_full)\n    \n    print(\"Prediction complete!\")\n    print(f\"Recommended Ensemble Prediction: €{ensemble_pred:.2f}/MWh\")\n    \n    return predictions, ensemble_pred, summary_df\n\n# --- 7. RUN PREDICTION ---\n\nif __name__ == \"__main__\":\n    # Predict for January 27, 2026\n    predictions, ensemble, summary = predict_electricity_price(\n        target_date='2026-01-27',\n        data_path='master_electricity_data.csv'\n    )\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"DONE! Check the generated visualization.\")\n    print(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:54:16.560190Z","iopub.execute_input":"2026-01-21T13:54:16.560456Z","iopub.status.idle":"2026-01-21T13:57:38.496614Z","shell.execute_reply.started":"2026-01-21T13:54:16.560432Z","shell.execute_reply":"2026-01-21T13:57:38.496028Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nELECTRICITY PRICE FORECASTING SYSTEM\n======================================================================\nLoading master dataset...\nLoaded 42,811 samples\nDate range: 2021-01-08 00:00:00 to 2025-12-31 23:00:00\n\nGenerating hourly predictions for 2026-01-27 (00:00 to 23:00)\n\nPredicting 637 hours ahead (from 2025-12-31 23:00:00 to 2026-01-27 12:00:00)\n\n[1/2] Training ARIMA model on full dataset...\nARIMA prediction for 2026-01-27 12:00:00: €86.67/MWh\n\n[2/2] Training SARIMA model on full dataset...\n(This may take several minutes...)\nSARIMA prediction for 2026-01-27 12:00:00: €65.36/MWh\n\n[3/4] Training Prophet model on full dataset...\n","output_type":"stream"},{"name":"stderr","text":"13:56:30 - cmdstanpy - INFO - Chain [1] start processing\n13:57:25 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"Prophet prediction for 2026-01-27 12:00:00: €94.48/MWh\n\n[4/4] Training LightGBM model on full dataset...\n\nNote: Using historical seasonal averages for renewable forecasts and load\n      (In production, use actual forecast data)\nLightGBM prediction for 2026-01-27 12:00:00: €79.49/MWh\n\n======================================================================\nELECTRICITY PRICE PREDICTIONS FOR 2026-01-27 12:00:00\n======================================================================\n   Model Predicted Price (€/MWh)\n   ARIMA                   86.67\n  SARIMA                   65.36\n Prophet                   94.48\nLightGBM                   79.49\n\n----------------------------------------------------------------------\nEnsemble Average:  €81.50/MWh\nStandard Deviation: €10.72/MWh\nRange:             €65.36 - €94.48/MWh\n======================================================================\n\nSaved visualization: prediction_2026-01-27 12:00:00.png\nPrediction complete!\nRecommended Ensemble Prediction: €81.50/MWh\n\n======================================================================\nDONE! Check the generated visualization.\n======================================================================\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}